
<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta charset="utf-8" />
    <title>Quality Gates Supported in the RefArch1.5 CI/CD Pipeline (Medusa) &#8212; DevGuide 1 documentation</title>
    <link rel="stylesheet" href="../_static/alabaster.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script type="text/javascript" src="../_static/jquery.js"></script>
    <script type="text/javascript" src="../_static/underscore.js"></script>
    <script type="text/javascript" src="../_static/doctools.js"></script>
    <script type="text/javascript" src="../_static/language_data.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
   
  <link rel="stylesheet" href="../_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <div class="section" id="quality-gates-supported-in-the-refarch1-5-ci-cd-pipeline-medusa">
<h1>Quality Gates Supported in the RefArch1.5 CI/CD Pipeline (Medusa)<a class="headerlink" href="#quality-gates-supported-in-the-refarch1-5-ci-cd-pipeline-medusa" title="Permalink to this headline">¶</a></h1>
<ul class="simple">
<li><p><a class="reference external" href="#test-stages">Test Stages</a></p></li>
<li><p><a class="reference external" href="#guidance-on-writing-tests-for-automated-quality-gates">Guidance on Writing Tests For Automated Quality Gates</a></p>
<ul>
<li><p><a class="reference external" href="#unit-tests">Unit Tests</a></p></li>
<li><p><a class="reference external" href="#integration-tests">Integration Tests</a></p></li>
<li><p><a class="reference external" href="#consumer-driven-contract-test-cdc">Consumer-driven Contract Test (CDC)</a></p></li>
<li><p><a class="reference external" href="#performance-tests-server-side">Performance Tests (Server-side)</a></p></li>
<li><p><a class="reference external" href="#performance-tests-client-side">Performance Tests (Client-side)</a></p></li>
<li><p><a class="reference external" href="#e2e-tests">E2E Tests</a></p></li>
</ul>
</li>
</ul>
<p><a class="reference external" href="https://github.com/EBSCOIS/platform.infrastructure.medusa">Medusa</a> is the pipeline library which orchestrates RefArch 1.5 CI/CD stages. This guide captures the various quality gates/test stages that will be supported by the library.</p>
<div class="section" id="test-stages">
<h2>Test Stages<a class="headerlink" href="#test-stages" title="Permalink to this headline">¶</a></h2>
<p><img alt="../_images/test-pyramid.png" src="../_images/test-pyramid.png" />Test Pyramid</p>
<table border="1" class="docutils">
<thead>
<tr>
<th>Test Category</th>
<th>Execution Stage</th>
<th>Required?</th>
<th>Purpose</th>
<th>Role of test doubles</th>
<th>Network calls guidance</th>
<th>Assertions</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="https://martinfowler.com/articles/practical-test-pyramid.html#UnitTests">Unit Tests</a></td>
<td>CI / pre-deploy</td>
<td>Yes</td>
<td>Fast, low-level tests to assert on the behavior of the code i.e., every model, class/controller, functions and view, in isolation.</td>
<td>see section below for guidance</td>
<td>No network calls made</td>
<td><li> Coverage (unit+integration) &gt;= 80% <li> % failed tests = 0% </ul></td>
</tr>
<tr>
<td><a href="https://martinfowler.com/articles/practical-test-pyramid.html#IntegrationTests">Integration Tests</a></td>
<td>CI / pre-deploy</td>
<td>Yes</td>
<td><a href="https://martinfowler.com/bliki/IntegrationTest.html">Narrow integration tests that live at the boundary of your service</a>, to validate component integration points.  The intent is to write integration tests for all pieces of code where you either serialize or de-serialize data.  some examples: <ul><li>Calls to your services' REST API<li>Reading from and writing to databases<li>Calling other application's APIs<li>Reading from and writing to queues<li>Writing to the filesystem</ul></td>
<td>see section below for guidance</td>
<td>Localhost only</td>
<td><li> Coverage (unit+integration) &gt;= 80% <li> % failed tests = 0%</ul></td>
</tr>
<tr>
<td><a href="http://confluence/display/~abhavan/Consumer+Driven+Contract+%28CDC%29+Testing">Consumer-driven Contract Test (CDC)</a></td>
<td>CI / pre-deploy</td>
<td>For producer services that expose interfaces to other services only.</td>
<td>Services that provide interfaces (providers/producers) fetch and run CDC tests continuously to spot any breaking changes immediately.  The <code>verifier tests</code> are auto-generated based on contracts expressed as DSL from the consumers.</td>
<td>see section below for guidance</td>
<td>Localhost only</td>
<td><ul><li> Coverage should focus on catching defects focus on catching defects <ul><li>within the consumer workflows<li>around misunderstandings regarding endpoint configuration or payload<li>when the provider has created breaking changes on endpoints and/or payload</ul><li> % failed tests = 0%</ul></td>
</tr>
<tr>
<td><a href="https://www.sonarqube.org/features/clean-code/">Static Code Analysis</a></td>
<td>CI / pre-deploy</td>
<td>Yes</td>
<td>Code quality analysis to measure test coverage, run security scans, look for code smells, etc. Please see this <a href="https://www.yammer.com/ebsco.com/#/Threads/show?threadId=1160757472&amp;amp;search_origin=global&amp;amp;scoring=linear1Y-prankie-group-private-higher&amp;amp;match=any-exact&amp;amp;search_sort=relevance&amp;amp;page=1&amp;amp;search=chris%20matheson">yammer</a> post for more information. <ul><li> Note: The quality profile for all projects is set to default to <a href="http://sonarqube73.eis-platformlive.cloud/quality_gates/show/2">EBSCO QGate</a>. If you need help changing this to a stricter profile for your project, please reach out to EA.</td>
<td>N/A</td>
<td>N/A</td>
<td><ul><li> Blocker issues = 0 <li> Coverage on new code &gt;= 80% <li> Security rating on new code = A+</ul></td>
</tr>
<tr>
<td><a href="https://martinfowler.com/articles/practical-test-pyramid.html#End-to-endTests">E2E Tests</a></td>
<td>CD / post-deploy</td>
<td>Yes</td>
<td>Reliable workflow(s) to smoke test the "ends" that the system touches i.e., downstream calls only.  e.g., middle-&gt;db, ui-&gt;edge-&gt;middle-&gt;db. This is meant to be a deployment qualification test to verify the container deployment worked and the application is up and able to receive requests and communicate with its dependencies.</td>
<td>see section below for guidance</td>
<td>Can access real services/external systems, databases, file systems, etc. over the network.</td>
<td>AT LEAST 1, key workflows for integration with external systems are covered</td>
</tr>
<tr>
<td><a href="http://confluence/display/~abhavan/Performance+Testing+Reference#PerformanceTestingReference-Server-sideperformancetesting">Server-side Performance Tests</a></td>
<td>CD/ post-deploy</td>
<td>Required (implicit perf validation via <code>Dark</code> release stage during hydra deployment is an option, but will need to be validated by your system architect for viability. Also, this is not viable until refarch1.5 is live and receiving customer traffic.)</td>
<td>Validate that the service is able to meet the performance goals (relative and absolute assertions against response time under load, error rate)</td>
<td>see section below for guidance</td>
<td>Can access real services/external systems, databases, file systems, etc. over the network</td>
<td>All key business transactions are covered to ensure compliance with perf goals as per the NFRs.</td>
</tr>
<tr>
<td><a href="http://confluence/display/~abhavan/Performance+Testing+Reference#PerformanceTestingReference-Client-sideperformancetesting">Client-side Performance Tests</a></td>
<td>CD/ post-deploy</td>
<td>Only for UX services</td>
<td>To opportunities around improving the end-user experience by identifying optimizations that can be applied to a UI page (mobile or desktop experience) to improve TTFB, render time, DOM load time (e.g., leveraging browser caching, enabling compression, minifying html/css, optimizing rendering experience by inlining JS or making external requests async, etc.)</td>
<td>see section below for guidance</td>
<td>Can access real services/external systems, databases, file systems, etc. over the network</td>
<td>All key business transactions are covered to ensure compliance with client-side perf goals as per the NFRs.</td>
</tr>
</tbody>
</table></div>
<div class="section" id="guidance-on-writing-tests-for-automated-quality-gates">
<h2>Guidance on Writing Tests For Automated Quality Gates<a class="headerlink" href="#guidance-on-writing-tests-for-automated-quality-gates" title="Permalink to this headline">¶</a></h2>
<div class="section" id="unit-tests">
<h3>Unit Tests<a class="headerlink" href="#unit-tests" title="Permalink to this headline">¶</a></h3>
<p><strong>Use of test doubles</strong></p>
<p>Aggressively mock all dependencies, including:</p>
<ul class="simple">
<li><p>external service dependencies (i.e. anything that crosses a process/network boundary)</p></li>
<li><p>external libraries</p></li>
<li><p>classes/ functions in the same project</p></li>
</ul>
</div>
<div class="section" id="integration-tests">
<h3>Integration Tests<a class="headerlink" href="#integration-tests" title="Permalink to this headline">¶</a></h3>
<p><strong>Use of test doubles</strong></p>
<p>Aim to run your external dependencies locally i.e., mock/stub dependencies not owned by the service, like:</p>
<ul class="simple">
<li><p>in-process test doubles to test integration with external systems e.g., in-memory embedded databases, local MySQL database, local ext4 filesystem</p></li>
<li><p>out-of-process stubs to replace an external service (recommended to use the stubs published by the producer service during the contract testing stage)</p></li>
</ul>
</div>
<div class="section" id="consumer-driven-contract-test-cdc">
<h3>Consumer-driven Contract Test (CDC)<a class="headerlink" href="#consumer-driven-contract-test-cdc" title="Permalink to this headline">¶</a></h3>
<p><strong>Use of test doubles</strong></p>
<p>The framework provides 2 frameworks to execute contract verifier tests:</p>
<ul class="simple">
<li><p>For gradle/maven based spring boot services, use MockMvc framework to mock dependencies.</p></li>
<li><p>For all others (e.g., nodejs or .NET), use stub servers to replace calls to external dependencies if CDC tests are run in non-MVC mode (i.e., explicit-mode). These are out-of-process test-doubles that help mock external service calls using reliable stubs published from the downstream producer’s contract test stage.</p></li>
</ul>
</div>
<div class="section" id="performance-tests-server-side">
<h3>Performance Tests (Server-side)<a class="headerlink" href="#performance-tests-server-side" title="Permalink to this headline">¶</a></h3>
<p><strong>Use of test doubles</strong></p>
<p>Recommendation is to write “narrow perf tests” to isolate measurements to service-under-test by using stubs to replace downstream dependencies. Watch this space for updates – more to come when we have examples/reference implementation for these scenarios).</p>
<p><strong>JMX Test Attributes</strong></p>
<ul class="simple">
<li><p>Please refer to the Medusa guide on <a class="reference external" href="https://github.com/EBSCOIS/platform.infrastructure.medusa#performance-tests">Performance Tests</a> for specifications around where the tests are discovered from and more about the performanceDefinition.yaml file.</p></li>
<li><p>The <code class="docutils literal notranslate"><span class="pre">TestProperties</span></code> section in the performanceDefinition file helps define the attributes of the jmeter test (<code class="docutils literal notranslate"><span class="pre">jmx</span></code> test plan) when Medusa orchestrates the test as an automated quality gate during the CD-phase of the pipeline.</p></li>
<li><p>In order for these properties to take effect, a matching JMeter property (referenced using <code class="docutils literal notranslate"><span class="pre">${__P(duration,60)}</span></code> in test plan, and passed into the command-line invokation of the jmx file using <code class="docutils literal notranslate"><span class="pre">-J</span></code> argument) should be present in the test plan.</p>
<ul>
<li><p>e.g., if <code class="docutils literal notranslate"><span class="pre">duration</span></code> is provided under the <code class="docutils literal notranslate"><span class="pre">TestProperties</span></code> section, the <code class="docutils literal notranslate"><span class="pre">jmx</span></code> test plan should implement and use the <code class="docutils literal notranslate"><span class="pre">-Jduration</span></code> property.</p></li>
</ul>
</li>
<li><p>Recommendations for performance tests in the pipeline:</p>
<ul>
<li><p>Provide <code class="docutils literal notranslate"><span class="pre">duration</span></code> in the <code class="docutils literal notranslate"><span class="pre">TestProperties</span></code> section, to limit the tests to a fixed duration.</p>
<ul>
<li><p>Minimum duration should be at least &gt;1 minute (i.e., 2x the prometheus scrape interval, which defaults to 30s), and maximum duration should be well under the &lt;15 minutes to stay within the <code class="docutils literal notranslate"><span class="pre">hydra</span></code> timeout setting for test jobs.</p></li>
<li><p>Recommended duration for tests is 5-10 minutes i.e., 300 seconds - 600 seconds.</p></li>
</ul>
</li>
<li><p>Provide <code class="docutils literal notranslate"><span class="pre">throughput</span></code>, <code class="docutils literal notranslate"><span class="pre">threads</span></code>, <code class="docutils literal notranslate"><span class="pre">rampup</span></code> (optional) attributes in the <code class="docutils literal notranslate"><span class="pre">jmx</span></code> test plan to help drive the load levels (<code class="docutils literal notranslate"><span class="pre">rps</span></code> or <code class="docutils literal notranslate"><span class="pre">requests</span> <span class="pre">per</span> <span class="pre">second</span></code>) for your tests.</p>
<ul>
<li><p>Recommendation is to use steady load (throughput) during these tests, instead of variable load since these are short-duration tests and variability in load levels can lead to inconsistent measurements on aggregate calculations of response time.</p></li>
<li><p>Ramp up/down can be used, but the validation currently does not offset these windows from calculating 95th percentile response time. This will be a future enhancement added to the platform (tentatively in PI14).</p></li>
<li><p>The <code class="docutils literal notranslate"><span class="pre">Constant</span> <span class="pre">Throughput</span> <span class="pre">Timer</span></code> element can be used to throttle/vary the request rates for the <code class="docutils literal notranslate"><span class="pre">HTTP</span> <span class="pre">Request</span></code> elements in the test plan. When this is applied at the <code class="docutils literal notranslate"><span class="pre">Thread</span> <span class="pre">Group</span></code> level it applies to all <code class="docutils literal notranslate"><span class="pre">HTTP</span> <span class="pre">Request</span></code> elements under that group, but you could use the timer within an <code class="docutils literal notranslate"><span class="pre">HTTP</span> <span class="pre">Request</span></code> element to apply a variable rate and override the parent-rate for specific requests within a thread group.</p></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
<div class="section" id="performance-tests-client-side">
<h3>Performance Tests (Client-side)<a class="headerlink" href="#performance-tests-client-side" title="Permalink to this headline">¶</a></h3>
<p>Recommendation is to follow this reference implementation from EA: <a class="reference external" href="https://github.com/EBSCOIS/platform.infrastructure.docker-lighthouse">platform.infrastructure.docker-lighthouse</a>.</p>
</div>
<div class="section" id="e2e-tests">
<h3>E2E Tests<a class="headerlink" href="#e2e-tests" title="Permalink to this headline">¶</a></h3>
<p>Typically, no test doubles/mocking recommended. The purpose of these tests is to test integration with external services, persistence, startup logic, authentication workflows, network configuration and remote request/response routing with dependencies.</p>
<p>For UX svcs: Validate limited user-critical workflows, to test integration with downstream dependencies. Model tests around users of the system and the journeys those users make through the system (business cases).</p>
<p>As an exception, mocking could be considered for async back-end processes and other flaky external services that might be part of the e2e workflow for the service. Refer guidance from Martin Fowler “If a particular external service or GUI is a major cause of flakiness in the test suite, it can help to redefine the test boundary to exclude the component. In this case, total end-to-end coverage is traded in favour of reliability in the suite. This is acceptable as long as other forms of testing verify the flaky component using different means.”</p>
<p>Please see this page for more guidance around e2e tests: <a class="reference external" href="http://confluence/display/~abhavan/E2E+Testing+for+Microservices">E2E Testing for Microservices</a></p>
</div>
</div>
</div>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="../index.html">DevGuide</a></h1>








<h3>Navigation</h3>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../index.html">Documentation overview</a><ul>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3>Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../search.html" method="get">
      <input type="text" name="q" />
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2019, Pavel.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 2.0.0</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.12</a>
      
      |
      <a href="../_sources/guides/Quality_Gates_Medusa.md.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>